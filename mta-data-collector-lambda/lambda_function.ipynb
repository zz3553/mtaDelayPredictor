{
 "cells": [
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-28T21:37:35.897952Z",
     "start_time": "2025-07-28T21:37:35.687632Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import csv\n",
    "import requests\n",
    "import zipfile\n",
    "import io\n",
    "from datetime import datetime\n",
    "from sqlalchemy import create_engine, text\n",
    "from nyct_gtfs import NYCTFeed\n",
    "from nyct_gtfs.gtfs_static_types import Stations"
   ],
   "id": "7199e4958c570bb2",
   "outputs": [],
   "execution_count": 1
  },
  {
   "cell_type": "code",
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2025-07-28T21:39:07.163095Z",
     "start_time": "2025-07-28T21:39:07.158792Z"
    }
   },
   "source": [
    "DB_USER = \"neondb_owner\"\n",
    "DB_PASSWORD = \"npg_J73HnAiwErpq\"\n",
    "DB_HOST = \"ep-spring-truth-ae312q45-pooler.c-2.us-east-2.aws.neon.tech\"\n",
    "DB_PORT = \"5432\"\n",
    "DB_NAME = \"neondb\"\n",
    "\n",
    "def log_with_time(message):\n",
    "    print(f\"[{datetime.now().strftime('%Y-%m-%d %H:%M:%S.%f')[:-3]}] {message}\")"
   ],
   "outputs": [],
   "execution_count": 2
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-28T21:43:13.512696Z",
     "start_time": "2025-07-28T21:43:13.504820Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def process_trains(train_list, direction):\n",
    "    results = []\n",
    "    log_with_time(f\"Processing {len(train_list)} {direction}bound trains...\")\n",
    "    for i, train in enumerate(train_list):\n",
    "        print(train.trip_id)\n",
    "        trip_id = train.trip_id\n",
    "        stop_id = train.location\n",
    "        current_time = train.last_position_update\n",
    "\n",
    "        matching_schedule = schedule_index.get((trip_id, stop_id))\n",
    "        if matching_schedule:\n",
    "            try:\n",
    "                scheduled_time = datetime.strptime(matching_schedule[\"arrival_time\"], \"%H:%M:%S\").time()\n",
    "                scheduled_dt = datetime.combine(current_time.date(), scheduled_time)\n",
    "                delay = (current_time - scheduled_dt).total_seconds() / 60.0\n",
    "                station_name = stations.get_station_name(stop_id)\n",
    "                status = \"on_time\" if abs(delay) < 1 else \"delayed\" if delay > 0 else \"early\"\n",
    "\n",
    "                results.append({\n",
    "                    \"trip_id\": trip_id,\n",
    "                    \"stop_id\": stop_id,\n",
    "                    \"station_name\": station_name,\n",
    "                    \"timestamp\": current_time,\n",
    "                    \"delay_min\": round(delay, 2),\n",
    "                    \"status\": status,\n",
    "                    \"direction\": direction,\n",
    "                    \"stop_sequence\": int(matching_schedule.get(\"stop_sequence\", 0)),\n",
    "                    \"rush_hour\": \"morning\" if 7 <= current_time.hour < 10 else \"evening\" if 16 <= current_time.hour < 19 else None\n",
    "                })\n",
    "            except Exception as e:\n",
    "                log_with_time(f\"ERROR processing train {trip_id}: {e}\")\n",
    "        else:\n",
    "            log_with_time(f\"No schedule match for trip_id={trip_id}, stop_id={stop_id}\")\n",
    "\n",
    "        if (i + 1) % 5 == 0:\n",
    "            log_with_time(f\"Processed {i + 1}/{len(train_list)} {direction}bound trains\")\n",
    "    return results"
   ],
   "id": "5f73cbb9c5e1c09a",
   "outputs": [],
   "execution_count": 14
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-28T21:43:22.165757Z",
     "start_time": "2025-07-28T21:43:14.460521Z"
    }
   },
   "cell_type": "code",
   "source": [
    "log_with_time(\"Step 1: Fetching realtime MTA data...\")\n",
    "feed = NYCTFeed(\"N\")\n",
    "trains = feed.filter_trips(line_id=['N'], underway=True)\n",
    "northbound_trains = [t for t in trains if t.direction == 'N']\n",
    "southbound_trains = [t for t in trains if t.direction == 'S']   \n",
    "log_with_time(f\"Fetched {len(northbound_trains)} northbound and {len(southbound_trains)} southbound trains\")\n",
    "\n",
    "if not northbound_trains and not southbound_trains:\n",
    "    log_with_time(\"No trains currently underway - exiting early\")\n",
    "\n",
    "log_with_time(\"Step 2: Downloading GTFS static data...\")\n",
    "url = \"https://rrgtfsfeeds.s3.amazonaws.com/gtfs_supplemented.zip\"\n",
    "response = requests.get(url, timeout=30)\n",
    "response.raise_for_status()\n",
    "log_with_time(f\"Downloaded GTFS ZIP ({len(response.content):,} bytes)\")\n",
    "\n",
    "log_with_time(\"Step 3: Extracting and parsing stop_times.txt...\")\n",
    "with zipfile.ZipFile(io.BytesIO(response.content)) as zip_file:\n",
    "    stop_times_file_path = next((f for f in zip_file.namelist() if f.endswith('stop_times.txt')), None)\n",
    "    if not stop_times_file_path:\n",
    "        raise FileNotFoundError(\"stop_times.txt not found\")\n",
    "    log_with_time(f\"Found stop_times.txt at {stop_times_file_path}\")\n",
    "\n",
    "    with zip_file.open(stop_times_file_path) as stop_times_file:\n",
    "        csv_content = stop_times_file.read().decode('utf-8')\n",
    "        csv_reader = csv.DictReader(io.StringIO(csv_content))\n",
    "        schedule_index = {}\n",
    "        for i, row in enumerate(csv_reader):\n",
    "            trip_id = row.get(\"trip_id\")\n",
    "            stop_id = row.get(\"stop_id\")\n",
    "            if trip_id and stop_id:\n",
    "                schedule_index[(trip_id, stop_id)] = row\n",
    "            if i > 0 and i % 200000 == 0:\n",
    "                log_with_time(f\"Indexed {i:,} rows from stop_times.txt...\")\n",
    "        log_with_time(f\"Finished indexing stop_times.txt with {len(schedule_index):,} entries\")\n",
    "\n",
    "stations = Stations()\n",
    "\n",
    "log_with_time(\"Step 4: Calculating delays...\")\n",
    "all_results = process_trains(northbound_trains, \"N\") + process_trains(southbound_trains, \"S\")\n",
    "log_with_time(f\"Total delay records computed: {len(all_results):,}\")\n",
    "\n",
    "if not all_results:\n",
    "    log_with_time(\"No delay data found - exiting\")\n",
    "all_results"
   ],
   "id": "fe13b4e63ee1eed4",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2025-07-28 17:43:14.464] Step 1: Fetching realtime MTA data...\n",
      "[2025-07-28 17:43:14.616] Fetched 9 northbound and 10 southbound trains\n",
      "[2025-07-28 17:43:14.616] Step 2: Downloading GTFS static data...\n",
      "[2025-07-28 17:43:15.250] Downloaded GTFS ZIP (19,204,055 bytes)\n",
      "[2025-07-28 17:43:15.250] Step 3: Extracting and parsing stop_times.txt...\n",
      "[2025-07-28 17:43:15.251] Found stop_times.txt at stop_times.txt\n",
      "[2025-07-28 17:43:16.588] Indexed 200,000 rows from stop_times.txt...\n",
      "[2025-07-28 17:43:17.099] Indexed 400,000 rows from stop_times.txt...\n",
      "[2025-07-28 17:43:17.647] Indexed 600,000 rows from stop_times.txt...\n",
      "[2025-07-28 17:43:18.200] Indexed 800,000 rows from stop_times.txt...\n",
      "[2025-07-28 17:43:18.729] Indexed 1,000,000 rows from stop_times.txt...\n",
      "[2025-07-28 17:43:19.270] Indexed 1,200,000 rows from stop_times.txt...\n",
      "[2025-07-28 17:43:19.847] Indexed 1,400,000 rows from stop_times.txt...\n",
      "[2025-07-28 17:43:20.383] Indexed 1,600,000 rows from stop_times.txt...\n",
      "[2025-07-28 17:43:20.909] Indexed 1,800,000 rows from stop_times.txt...\n",
      "[2025-07-28 17:43:21.440] Indexed 2,000,000 rows from stop_times.txt...\n",
      "[2025-07-28 17:43:21.979] Indexed 2,200,000 rows from stop_times.txt...\n",
      "[2025-07-28 17:43:22.155] Finished indexing stop_times.txt with 2,266,327 entries\n",
      "[2025-07-28 17:43:22.160] Step 4: Calculating delays...\n",
      "[2025-07-28 17:43:22.160] Processing 9 Nbound trains...\n",
      "098800_N..N33R\n",
      "[2025-07-28 17:43:22.160] No schedule match for trip_id=098800_N..N33R, stop_id=R03N\n",
      "099300_N..N33R\n",
      "[2025-07-28 17:43:22.160] No schedule match for trip_id=099300_N..N33R, stop_id=R04N\n",
      "100200_N..N16R\n",
      "[2025-07-28 17:43:22.160] No schedule match for trip_id=100200_N..N16R, stop_id=B08N\n",
      "101200_N..N33R\n",
      "[2025-07-28 17:43:22.160] No schedule match for trip_id=101200_N..N33R, stop_id=R15N\n",
      "101900_N..N33R\n",
      "[2025-07-28 17:43:22.160] No schedule match for trip_id=101900_N..N33R, stop_id=R20N\n",
      "[2025-07-28 17:43:22.160] Processed 5/9 Nbound trains\n",
      "102700_N..N33R\n",
      "[2025-07-28 17:43:22.160] No schedule match for trip_id=102700_N..N33R, stop_id=R31N\n",
      "103300_N..N33R\n",
      "[2025-07-28 17:43:22.160] No schedule match for trip_id=103300_N..N33R, stop_id=R31N\n",
      "104400_N..N33R\n",
      "[2025-07-28 17:43:22.160] No schedule match for trip_id=104400_N..N33R, stop_id=N02N\n",
      "105500_N..N33R\n",
      "[2025-07-28 17:43:22.160] No schedule match for trip_id=105500_N..N33R, stop_id=N08N\n",
      "[2025-07-28 17:43:22.160] Processing 10 Sbound trains...\n",
      "100100_N..S16R\n",
      "[2025-07-28 17:43:22.160] No schedule match for trip_id=100100_N..S16R, stop_id=N10S\n",
      "099650_N..S34R\n",
      "[2025-07-28 17:43:22.160] No schedule match for trip_id=099650_N..S34R, stop_id=N09S\n",
      "101100_N..S34R\n",
      "[2025-07-28 17:43:22.160] No schedule match for trip_id=101100_N..S34R, stop_id=N06S\n",
      "101400_N..S16R\n",
      "[2025-07-28 17:43:22.160] No schedule match for trip_id=101400_N..S16R, stop_id=N03S\n",
      "101600_N..S34R\n",
      "[2025-07-28 17:43:22.161] No schedule match for trip_id=101600_N..S34R, stop_id=R36S\n",
      "[2025-07-28 17:43:22.161] Processed 5/10 Sbound trains\n",
      "102200_N..S34R\n",
      "[2025-07-28 17:43:22.161] No schedule match for trip_id=102200_N..S34R, stop_id=Q01S\n",
      "102900_N..S34R\n",
      "[2025-07-28 17:43:22.161] No schedule match for trip_id=102900_N..S34R, stop_id=Q01S\n",
      "103750_N..S34R\n",
      "[2025-07-28 17:43:22.161] No schedule match for trip_id=103750_N..S34R, stop_id=R17S\n",
      "104550_N..S34R\n",
      "[2025-07-28 17:43:22.161] No schedule match for trip_id=104550_N..S34R, stop_id=R13S\n",
      "105400_N..S34R\n",
      "[2025-07-28 17:43:22.161] No schedule match for trip_id=105400_N..S34R, stop_id=R08S\n",
      "[2025-07-28 17:43:22.161] Processed 10/10 Sbound trains\n",
      "[2025-07-28 17:43:22.161] Total delay records computed: 0\n",
      "[2025-07-28 17:43:22.161] No delay data found - exiting\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[]"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 15
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "\n",
    "log_with_time(\"Step 5: Connecting to database...\")\n",
    "engine = create_engine(f\"postgresql://{DB_USER}:{DB_PASSWORD}@{DB_HOST}:{DB_PORT}/{DB_NAME}\")\n",
    "with engine.connect() as conn:\n",
    "    conn.execute(text(\"\"\"\n",
    "        CREATE TABLE IF NOT EXISTS train_delays (\n",
    "            id SERIAL PRIMARY KEY,\n",
    "            trip_id TEXT,\n",
    "            stop_id TEXT,\n",
    "            station_name TEXT,\n",
    "            timestamp TIMESTAMP,\n",
    "            delay_min REAL,\n",
    "            status TEXT,\n",
    "            direction TEXT,\n",
    "            stop_sequence INTEGER,\n",
    "            rush_hour TEXT\n",
    "        )\n",
    "    \"\"\"))\n",
    "    log_with_time(\"Database table verified\")\n",
    "\n",
    "    insert_sql = text(\"\"\"\n",
    "        INSERT INTO train_delays (\n",
    "            trip_id, stop_id, station_name, timestamp,\n",
    "            delay_min, status, direction, stop_sequence, rush_hour\n",
    "        ) VALUES (\n",
    "            :trip_id, :stop_id, :station_name, :timestamp,\n",
    "            :delay_min, :status, :direction, :stop_sequence, :rush_hour\n",
    "        )\n",
    "    \"\"\")\n",
    "\n",
    "    batch_size = 500\n",
    "    for i in range(0, len(all_results), batch_size):\n",
    "        batch = all_results[i:i + batch_size]\n",
    "        try:\n",
    "            conn.execute(insert_sql, batch)\n",
    "            log_with_time(f\"Inserted batch {(i // batch_size) + 1} of {len(batch)} records\")\n",
    "        except Exception as e:\n",
    "            log_with_time(f\"Insert error in batch {(i // batch_size) + 1}: {e}\")\n",
    "    conn.commit()\n",
    "    log_with_time(\"All batches committed\")"
   ],
   "id": "57bcd6d29ffe0c75"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
