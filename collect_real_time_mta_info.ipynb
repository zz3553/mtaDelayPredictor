{
 "cells": [
  {
   "cell_type": "code",
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2025-07-22T21:11:44.792388Z",
     "start_time": "2025-07-22T21:11:44.634599Z"
    }
   },
   "source": [
    "\"\"\"\n",
    "Getting realtime data feed from the MTA and separating based on N/S Bound trains\n",
    "\"\"\"\n",
    "from nyct_gtfs import NYCTFeed\n",
    "\n",
    "feed = NYCTFeed(\"N\")\n",
    "trains = feed.filter_trips(line_id=['N'], underway=True)\n",
    "\n",
    "# filtering based on n/s bound trains\n",
    "northbound_trains = [train for train in trains if train.direction == 'N']\n",
    "southbound_trains = [train for train in trains if train.direction == 'S']\n",
    "\n",
    "# gathering all the individual trips\n",
    "n_bound_trip_ids = [trip.trip_id for trip in northbound_trains]\n",
    "s_bound_trip_ids = [trip.trip_id for trip in southbound_trains]\n",
    "\n",
    "n_bound_trip_ids + s_bound_trip_ids"
   ],
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['098150_N..N33R',\n",
       " '098800_N..N33R',\n",
       " '099300_N..N33R',\n",
       " '100200_N..N16R',\n",
       " '101200_N..N33R',\n",
       " '101900_N..N33R',\n",
       " '102700_N..N33R',\n",
       " '090650_N..S34R',\n",
       " '092250_N..S34R',\n",
       " '092900_N..S34R',\n",
       " '093750_N..S34R',\n",
       " '094500_N..S34R',\n",
       " '095450_N..S34R',\n",
       " '097000_N..S34R',\n",
       " '097100_N..S16R',\n",
       " '098400_N..S',\n",
       " '099000_N..S34R',\n",
       " '100100_N..S16R',\n",
       " '101100_N..S34R',\n",
       " '101600_N..S34R',\n",
       " '102200_N..S34R']"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 43
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-22T21:12:02.949440Z",
     "start_time": "2025-07-22T21:11:47.384583Z"
    }
   },
   "cell_type": "code",
   "source": [
    "\"\"\"\n",
    "Creating data frame to hold scheduled times for each trip\n",
    "Downloads GTFS data from https://rrgtfsfeeds.s3.amazonaws.com/gtfs_supplemented.zip\n",
    "\"\"\"\n",
    "import pandas as pd\n",
    "import re\n",
    "import requests\n",
    "import zipfile\n",
    "import io\n",
    "import os\n",
    "from datetime import datetime\n",
    "\n",
    "# Define the absolute path to your project directory\n",
    "PROJECT_DIR = \"/Users/mitchel/Desktop/beep/mtaDelayPredictor\"\n",
    "DATA_DIR = os.path.join(PROJECT_DIR, \"data_files\")\n",
    "\n",
    "# Create data_files directory if it doesn't exist\n",
    "os.makedirs(DATA_DIR, exist_ok=True)\n",
    "\n",
    "# Download and extract the GTFS data\n",
    "print(\"Downloading GTFS data...\")\n",
    "url = \"https://rrgtfsfeeds.s3.amazonaws.com/gtfs_supplemented.zip\"\n",
    "response = requests.get(url)\n",
    "response.raise_for_status()  # Raise an exception for bad status codes\n",
    "\n",
    "# Extract stop_times.txt from the zip file\n",
    "print(\"Extracting stop_times.txt...\")\n",
    "with zipfile.ZipFile(io.BytesIO(response.content)) as zip_file:\n",
    "    # First, let's see what files are in the archive\n",
    "    file_list = zip_file.namelist()\n",
    "    # print(\"Files in archive:\", file_list)\n",
    "    \n",
    "    # Find the stop_times.txt file (it might be in a different path)\n",
    "    stop_times_file_path = None\n",
    "    for file_path in file_list:\n",
    "        if file_path.endswith('stop_times.txt'):\n",
    "            stop_times_file_path = file_path\n",
    "            break\n",
    "    \n",
    "    if stop_times_file_path is None:\n",
    "        raise FileNotFoundError(\"stop_times.txt not found in the archive\")\n",
    "    \n",
    "    # print(f\"Found stop_times.txt at: {stop_times_file_path}\")\n",
    "    \n",
    "    with zip_file.open(stop_times_file_path) as stop_times_file:\n",
    "        # Read the content and create a DataFrame\n",
    "        stop_times = pd.read_csv(stop_times_file)\n",
    "\n",
    "# Generate filename with current datetime\n",
    "current_datetime = datetime.now().strftime(\"%m_%d_%Y_%H_%M\")\n",
    "filename = os.path.join(DATA_DIR, f'stop_times_{current_datetime}.csv')\n",
    "\n",
    "# Get the absolute path for clarity\n",
    "abs_filename = os.path.abspath(filename)\n",
    "\n",
    "# Save to CSV with datetime appended\n",
    "print(f\"Saving to {abs_filename}...\")\n",
    "stop_times.to_csv(filename, index=False)\n",
    "\n",
    "# Verify the file was created\n",
    "if os.path.exists(filename):\n",
    "    file_size = os.path.getsize(filename)\n",
    "    print(f\"Successfully saved stop_times data to {abs_filename}\")\n",
    "    print(f\"File size: {file_size:,} bytes\")\n",
    "    print(f\"Number of rows: {len(stop_times):,}\")\n",
    "else:\n",
    "    print(f\"ERROR: File was not created at {abs_filename}\")\n",
    "    print(f\"Current working directory: {os.getcwd()}\")\n",
    "    print(f\"Contents of data_files directory: {os.listdir(DATA_DIR) if os.path.exists(DATA_DIR) else 'Directory does not exist'}\")\n",
    "\n",
    "\n",
    "if n_bound_trip_ids or s_bound_trip_ids:\n",
    "    trip_dfs = {}\n",
    "    all_trip_ids = n_bound_trip_ids + s_bound_trip_ids\n",
    "    \n",
    "    for trip in all_trip_ids:\n",
    "        escaped_trip = re.escape(trip)\n",
    "        filtered = stop_times[stop_times['trip_id'].str.contains(escaped_trip, na=False)]\n",
    "        trip_dfs[trip] = filtered\n",
    "        \n",
    "    print(f\"Processed {len(trip_dfs)} trip DataFrames\")\n",
    "else:\n",
    "    print(\"No trip IDs defined - skipping trip processing\")"
   ],
   "id": "8e8fd6a1b6fa38fa",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading GTFS data...\n",
      "Extracting stop_times.txt...\n",
      "Saving to /Users/mitchel/Desktop/beep/mtaDelayPredictor/data_files/stop_times_07_22_2025_17_11.csv...\n",
      "Successfully saved stop_times data to /Users/mitchel/Desktop/beep/mtaDelayPredictor/data_files/stop_times_07_22_2025_17_11.csv\n",
      "File size: 136,082,764 bytes\n",
      "Number of rows: 2,297,464\n",
      "Processed 21 trip DataFrames\n"
     ]
    }
   ],
   "execution_count": 44
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-22T20:31:39.469733Z",
     "start_time": "2025-07-22T20:31:17.367144Z"
    }
   },
   "cell_type": "code",
   "source": [
    "\"\"\"\n",
    "Combining static and real time schedule to compute delay information\n",
    "\"\"\"\n",
    "import pandas as pd\n",
    "from nyct_gtfs.gtfs_static_types import Stations\n",
    "\n",
    "stations = Stations()\n",
    "\n",
    "\n",
    "# === Shared delay calculation logic ===\n",
    "def process_trains(train_list, direction_label):\n",
    "    results = []\n",
    "\n",
    "    for train in train_list:\n",
    "        trip_id = train.trip_id\n",
    "        current_time = train.last_position_update\n",
    "        stop_id = train.location\n",
    "\n",
    "        if stop_id and trip_id:\n",
    "            sched = stop_times[\n",
    "                stop_times.trip_id.str.contains(trip_id, na=False) &\n",
    "                (stop_times.stop_id == stop_id)\n",
    "            ][[\"arrival_time\", \"departure_time\"]]\n",
    "\n",
    "            if not sched.empty:\n",
    "                try:\n",
    "                    scheduled_time = datetime.datetime.strptime(sched[\"arrival_time\"].iloc[0], \"%H:%M:%S\").time()\n",
    "                    scheduled_dt = pd.Timestamp.combine(current_time.date(), scheduled_time)\n",
    "                    delay = (current_time - scheduled_dt).total_seconds() / 60.0\n",
    "\n",
    "                    results.append({\n",
    "                        \"trip_id\": trip_id,\n",
    "                        \"stop_id_raw\": stop_id,\n",
    "                        \"stop_id\": stations.get_station_name(stop_id),\n",
    "                        \"timestamp\": current_time,\n",
    "                        \"delay_min\": round(delay,2),\n",
    "                        \"status\": \"on_time\" if abs(delay) < 1 else \"delayed\" if delay > 0 else \"early\",\n",
    "                        \"direction\": direction_label\n",
    "                    })\n",
    "                except Exception as e:\n",
    "                    print(f\"Error parsing time for {trip_id} at {stop_id}: {e}\")\n",
    "\n",
    "    df = pd.DataFrame(results)\n",
    "\n",
    "    # Add stop_sequence by fuzzy match\n",
    "    def get_stop_sequence(row):\n",
    "        match = stop_times[\n",
    "            stop_times.trip_id.str.contains(row[\"trip_id\"], na=False) &\n",
    "            (stop_times.stop_id == row[\"stop_id_raw\"])\n",
    "        ]\n",
    "        if not match.empty:\n",
    "            return match.iloc[0][\"stop_sequence\"]\n",
    "        else:\n",
    "            return None\n",
    "\n",
    "    df[\"stop_sequence\"] = df.apply(get_stop_sequence, axis=1)\n",
    "    df = df.sort_values(by=[\"trip_id\", \"stop_sequence\"]).reset_index(drop=True)\n",
    "\n",
    "    return df\n",
    "\n",
    "\n",
    "# === Run for both directions ===\n",
    "northbound_df = process_trains(northbound_trains, direction_label=\"N\")\n",
    "southbound_df = process_trains(southbound_trains, direction_label=\"S\")\n",
    "\n",
    "# === Combine for full view ===\n",
    "all_delays_df = pd.concat([northbound_df, southbound_df]).sort_values(by=[\"trip_id\", \"stop_sequence\"]).reset_index(drop=True)\n",
    "\n",
    "# === Rush hour logic ===\n",
    "def classify_rush_hour(ts):\n",
    "    hour = ts.hour\n",
    "    if 7 <= hour < 10:\n",
    "        return \"morning\"\n",
    "    elif 16 <= hour < 19:\n",
    "        return \"evening\"\n",
    "    else:\n",
    "        return None\n",
    "    \n",
    "# === Log ===\n",
    "all_delays_df[\"rush_hour\"] = all_delays_df[\"timestamp\"].apply(classify_rush_hour)\n",
    "\n",
    "all_delays_df"
   ],
   "id": "3c4f53dd78c35d3a",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "           trip_id stop_id_raw                    stop_id           timestamp  \\\n",
       "0   082650_N..S34R        N09S                   Avenue U 2025-07-22 16:30:48   \n",
       "1   088400_N..S34R        N10S                      86 St 2025-07-22 16:30:42   \n",
       "2   089250_N..S34R        N10S                      86 St 2025-07-22 16:26:50   \n",
       "3   089850_N..S34R        N07S                   Bay Pkwy 2025-07-22 16:30:45   \n",
       "4   090650_N..S34R        N05S                      18 Av 2025-07-22 16:30:48   \n",
       "5   092250_N..S34R        R41S                      59 St 2025-07-22 16:30:48   \n",
       "6   092900_N..S34R        R36S                      36 St 2025-07-22 16:30:15   \n",
       "7   093750_N..S34R        R36S                      36 St 2025-07-22 16:30:48   \n",
       "8   093900_N..N35R        R15N                      49 St 2025-07-22 16:30:48   \n",
       "9   094500_N..S34R        Q01S                   Canal St 2025-07-22 16:23:45   \n",
       "10  095450_N..S34R        Q01S                   Canal St 2025-07-22 16:29:20   \n",
       "11  097100_N..S16R        Q01S                   Canal St 2025-07-22 16:30:48   \n",
       "12  098150_N..N33R        N07N                   Bay Pkwy 2025-07-22 16:30:48   \n",
       "13     098400_N..S        N04S             New Utrecht Av 2025-07-22 16:29:34   \n",
       "14  098800_N..N33R        D43N  Coney Island-Stillwell Av 2025-07-22 16:28:25   \n",
       "\n",
       "    delay_min   status direction  stop_sequence rush_hour  \n",
       "0       95.80  delayed         S             26   evening  \n",
       "1       35.70  delayed         S             27   evening  \n",
       "2       24.33  delayed         S             27   evening  \n",
       "3       29.75  delayed         S             24   evening  \n",
       "4       24.80  delayed         S             22   evening  \n",
       "5       14.80  delayed         S             18   evening  \n",
       "6       13.25  delayed         S             17   evening  \n",
       "7        1.30  delayed         S             17   evening  \n",
       "8        1.80  delayed         N             17   evening  \n",
       "9        7.75  delayed         S             15   evening  \n",
       "10       3.33  delayed         S             15   evening  \n",
       "11      -0.70  on_time         S              9   evening  \n",
       "12       0.30  on_time         N              5   evening  \n",
       "13     -55.43    early         S             27   evening  \n",
       "14       0.42  on_time         N              1   evening  "
      ],
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>trip_id</th>\n",
       "      <th>stop_id_raw</th>\n",
       "      <th>stop_id</th>\n",
       "      <th>timestamp</th>\n",
       "      <th>delay_min</th>\n",
       "      <th>status</th>\n",
       "      <th>direction</th>\n",
       "      <th>stop_sequence</th>\n",
       "      <th>rush_hour</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>082650_N..S34R</td>\n",
       "      <td>N09S</td>\n",
       "      <td>Avenue U</td>\n",
       "      <td>2025-07-22 16:30:48</td>\n",
       "      <td>95.80</td>\n",
       "      <td>delayed</td>\n",
       "      <td>S</td>\n",
       "      <td>26</td>\n",
       "      <td>evening</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>088400_N..S34R</td>\n",
       "      <td>N10S</td>\n",
       "      <td>86 St</td>\n",
       "      <td>2025-07-22 16:30:42</td>\n",
       "      <td>35.70</td>\n",
       "      <td>delayed</td>\n",
       "      <td>S</td>\n",
       "      <td>27</td>\n",
       "      <td>evening</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>089250_N..S34R</td>\n",
       "      <td>N10S</td>\n",
       "      <td>86 St</td>\n",
       "      <td>2025-07-22 16:26:50</td>\n",
       "      <td>24.33</td>\n",
       "      <td>delayed</td>\n",
       "      <td>S</td>\n",
       "      <td>27</td>\n",
       "      <td>evening</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>089850_N..S34R</td>\n",
       "      <td>N07S</td>\n",
       "      <td>Bay Pkwy</td>\n",
       "      <td>2025-07-22 16:30:45</td>\n",
       "      <td>29.75</td>\n",
       "      <td>delayed</td>\n",
       "      <td>S</td>\n",
       "      <td>24</td>\n",
       "      <td>evening</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>090650_N..S34R</td>\n",
       "      <td>N05S</td>\n",
       "      <td>18 Av</td>\n",
       "      <td>2025-07-22 16:30:48</td>\n",
       "      <td>24.80</td>\n",
       "      <td>delayed</td>\n",
       "      <td>S</td>\n",
       "      <td>22</td>\n",
       "      <td>evening</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>092250_N..S34R</td>\n",
       "      <td>R41S</td>\n",
       "      <td>59 St</td>\n",
       "      <td>2025-07-22 16:30:48</td>\n",
       "      <td>14.80</td>\n",
       "      <td>delayed</td>\n",
       "      <td>S</td>\n",
       "      <td>18</td>\n",
       "      <td>evening</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>092900_N..S34R</td>\n",
       "      <td>R36S</td>\n",
       "      <td>36 St</td>\n",
       "      <td>2025-07-22 16:30:15</td>\n",
       "      <td>13.25</td>\n",
       "      <td>delayed</td>\n",
       "      <td>S</td>\n",
       "      <td>17</td>\n",
       "      <td>evening</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>093750_N..S34R</td>\n",
       "      <td>R36S</td>\n",
       "      <td>36 St</td>\n",
       "      <td>2025-07-22 16:30:48</td>\n",
       "      <td>1.30</td>\n",
       "      <td>delayed</td>\n",
       "      <td>S</td>\n",
       "      <td>17</td>\n",
       "      <td>evening</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>093900_N..N35R</td>\n",
       "      <td>R15N</td>\n",
       "      <td>49 St</td>\n",
       "      <td>2025-07-22 16:30:48</td>\n",
       "      <td>1.80</td>\n",
       "      <td>delayed</td>\n",
       "      <td>N</td>\n",
       "      <td>17</td>\n",
       "      <td>evening</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>094500_N..S34R</td>\n",
       "      <td>Q01S</td>\n",
       "      <td>Canal St</td>\n",
       "      <td>2025-07-22 16:23:45</td>\n",
       "      <td>7.75</td>\n",
       "      <td>delayed</td>\n",
       "      <td>S</td>\n",
       "      <td>15</td>\n",
       "      <td>evening</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>095450_N..S34R</td>\n",
       "      <td>Q01S</td>\n",
       "      <td>Canal St</td>\n",
       "      <td>2025-07-22 16:29:20</td>\n",
       "      <td>3.33</td>\n",
       "      <td>delayed</td>\n",
       "      <td>S</td>\n",
       "      <td>15</td>\n",
       "      <td>evening</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>097100_N..S16R</td>\n",
       "      <td>Q01S</td>\n",
       "      <td>Canal St</td>\n",
       "      <td>2025-07-22 16:30:48</td>\n",
       "      <td>-0.70</td>\n",
       "      <td>on_time</td>\n",
       "      <td>S</td>\n",
       "      <td>9</td>\n",
       "      <td>evening</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>098150_N..N33R</td>\n",
       "      <td>N07N</td>\n",
       "      <td>Bay Pkwy</td>\n",
       "      <td>2025-07-22 16:30:48</td>\n",
       "      <td>0.30</td>\n",
       "      <td>on_time</td>\n",
       "      <td>N</td>\n",
       "      <td>5</td>\n",
       "      <td>evening</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>098400_N..S</td>\n",
       "      <td>N04S</td>\n",
       "      <td>New Utrecht Av</td>\n",
       "      <td>2025-07-22 16:29:34</td>\n",
       "      <td>-55.43</td>\n",
       "      <td>early</td>\n",
       "      <td>S</td>\n",
       "      <td>27</td>\n",
       "      <td>evening</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>098800_N..N33R</td>\n",
       "      <td>D43N</td>\n",
       "      <td>Coney Island-Stillwell Av</td>\n",
       "      <td>2025-07-22 16:28:25</td>\n",
       "      <td>0.42</td>\n",
       "      <td>on_time</td>\n",
       "      <td>N</td>\n",
       "      <td>1</td>\n",
       "      <td>evening</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 36
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-22T20:31:39.821878Z",
     "start_time": "2025-07-22T20:31:39.792183Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import datetime\n",
    "import pandas as pd\n",
    "from sqlalchemy import create_engine, text\n",
    "\n",
    "# === Database config ===\n",
    "DB_USER = \"postgres\"\n",
    "DB_PASSWORD = \"commiteveryday\"\n",
    "DB_HOST = \"localhost\"\n",
    "DB_PORT = \"5432\"\n",
    "DB_NAME = \"train_delays\"\n",
    "\n",
    "# === Create DB engine ===\n",
    "engine = create_engine(f\"postgresql://{DB_USER}:{DB_PASSWORD}@{DB_HOST}:{DB_PORT}/{DB_NAME}\")\n",
    "\n",
    "# === Create tables ===\n",
    "create_train_delays = \"\"\"\n",
    "CREATE TABLE IF NOT EXISTS train_delays (\n",
    "    id SERIAL PRIMARY KEY,\n",
    "    trip_id TEXT,\n",
    "    stop_id TEXT,\n",
    "    station_name TEXT,\n",
    "    timestamp TIMESTAMP,\n",
    "    delay_min REAL,\n",
    "    status TEXT,\n",
    "    direction TEXT,\n",
    "    stop_sequence INTEGER,\n",
    "    rush_hour TEXT\n",
    ");\n",
    "\"\"\"\n",
    "\n",
    "with engine.connect() as conn:\n",
    "    conn.execute(text(create_train_delays))\n",
    "    print(\"Table created.\")\n",
    "\n",
    "# === Clean and insert delay data ===\n",
    "if not all_delays_df.empty:\n",
    "    delay_cols = ['trip_id', 'stop_id_raw', 'stop_id', 'timestamp', 'delay_min', 'status', 'direction', 'stop_sequence', 'rush_hour']\n",
    "    df = all_delays_df[delay_cols].copy()\n",
    "    df.columns = ['trip_id', 'stop_id', 'station_name', 'timestamp', 'delay_min', 'status', 'direction', 'stop_sequence', 'rush_hour']\n",
    "    df.to_sql('train_delays', engine, if_exists='append', index=False)\n",
    "    print(f\"Inserted {len(df)} delay records.\")\n",
    "else:\n",
    "    print(\"No delay data found.\")"
   ],
   "id": "f844f0465296e781",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Table created.\n",
      "Inserted 15 delay records.\n"
     ]
    }
   ],
   "execution_count": 37
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "\"\"\"\n",
    "Build Hourly Features + Labels from Postgres\n",
    "\"\"\"\n",
    "import pandas as pd\n",
    "\n",
    "# === Get hourly aggregated delay data ===\n",
    "delay_sql = \"\"\"\n",
    "    SELECT \n",
    "        DATE_TRUNC('hour', timestamp) AS hour,\n",
    "        COUNT(*) FILTER (WHERE delay_min > 1) * 1.0 / COUNT(*) AS delay_rate,\n",
    "        COUNT(*) AS total_trips,\n",
    "        MAX(rush_hour) AS rush_hour  -- could be 'morning', 'evening', or NULL\n",
    "    FROM train_delays\n",
    "    GROUP BY hour\n",
    "    ORDER BY hour\n",
    "\"\"\"\n",
    "\n",
    "# === Get matching weather data ===\n",
    "weather_sql = \"\"\"\n",
    "    SELECT \n",
    "        time AS hour,\n",
    "        temperature_f,\n",
    "        precipitation,\n",
    "        snowfall,\n",
    "        humidity,\n",
    "        windspeed\n",
    "    FROM weather_hourly\n",
    "\"\"\"\n",
    "\n",
    "# === Load from Postgres ===\n",
    "df_delays = pd.read_sql(delay_sql, engine)\n",
    "df_weather = pd.read_sql(weather_sql, engine)\n",
    "\n",
    "# === Merge both datasets on hour\n",
    "df = pd.merge(df_delays, df_weather, on=\"hour\", how=\"inner\")\n",
    "\n",
    "# === Add time-based features\n",
    "df[\"hour_of_day\"] = df[\"hour\"].dt.hour\n",
    "df[\"day_of_week\"] = df[\"hour\"].dt.dayofweek\n",
    "df[\"is_weekend\"] = df[\"day_of_week\"].isin([5, 6]).astype(int)\n",
    "\n",
    "# === Drop incomplete rows\n",
    "df = df.dropna()\n",
    "\n",
    "# === Show preview\n",
    "print(df.head())"
   ],
   "id": "fc9399e135b20d9e"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
